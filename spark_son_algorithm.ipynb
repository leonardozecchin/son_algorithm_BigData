{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a671e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58720a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../datasets/'\n",
    "name_file = 'accidents.dat'\n",
    "path_file = directory + name_file\n",
    "num_partition = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec336f9",
   "metadata": {},
   "source": [
    "Qui va specificato il delimitatore per il file su cui si sta lavorando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_delimiter = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b08d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile(path_file,num_partition).map(lambda line: line.split())#.map(lambda item: map(int,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d894f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb72170",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_supp_thresholds\n",
    "global_supp_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e884216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_singletons(baskets,local_threshold):\n",
    "    \"\"\"Funzione che prende calcola gli itemset di dimensione 1 che sono frequenti\n",
    "    Input:\n",
    "        - baskets, contiene gli itemset;\n",
    "        - local_threshold, la threshold per filtrare gli item che hanno un supporto maggiore di essa.\n",
    "    Output:\n",
    "        - singletons, lista che contiene gli item frequenti per i basket passati in input.\n",
    "    \"\"\"\n",
    "    candidates_dictionary = dict()\n",
    "    singletons = list()\n",
    "\n",
    "    for basket in baskets:\n",
    "        for item in basket:\n",
    "            if item not in candidates_dictionary.keys():\n",
    "                candidates_dictionary[item] = 1\n",
    "            else:\n",
    "                candidates_dictionary[item] += 1\n",
    "    \n",
    "    for key,value in candidates_dictionary.items():\n",
    "        if value >= local_threshold:\n",
    "            singletons.append(key)\n",
    "    \n",
    "    return sorted(singletons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa272466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequents(baskets, prev_freq, dim,local_threshold):\n",
    "    \"\"\"Funzione la quale calcola gli itemset frequenti di dimensione maggiore di 1.\n",
    "    Input:\n",
    "        - basket, insieme di itemset su cui stiamo lavorando;\n",
    "        - prev_freq, gli itemset frequenti di dimensione dim-1;\n",
    "        - dim, la dimensione attuale;\n",
    "        - local_threshold, minimo supporto che gli itemset devono superare o raggiungere per essere\n",
    "            considerati frequenti\n",
    "    Output:\n",
    "        - freq_itemsets, lista degli itemset frequenti\n",
    "    \"\"\"\n",
    "    candidates = list()\n",
    "    dict_table = dict()\n",
    "    freq_itemsets = list()\n",
    "    if dim==2:\n",
    "        table_C2 = itertools.combinations(prev_freq,dim)\n",
    "        for element in table_C2:\n",
    "            candidates.append(element)\n",
    "    else:\n",
    "        for item in itertools.combinations(prev_freq,2):\n",
    "            if(len(set(item[0]).intersection(set(item[1]))) == dim-2):\n",
    "                candidate_itemsets = tuple(set(item[0]).union(set(item[1])))\n",
    "                if candidate_itemsets in candidates:\n",
    "                    continue\n",
    "                else:\n",
    "                    pair = itertools.combinations(candidate_itemsets,dim-1)\n",
    "                    \n",
    "                    if set(pair).issubset(prev_freq):\n",
    "                        candidates.append(candidate_itemsets)\n",
    "                    \n",
    "    for candidate in candidates:\n",
    "        for basket in baskets:\n",
    "            if set(candidate).issubset(set(basket)):\n",
    "                dict_table.setdefault(candidate,0)\n",
    "                dict_table[candidate] +=1\n",
    "\n",
    "    for key,value in dict_table.items():\n",
    "        if value >= local_threshold:\n",
    "            freq_itemsets.append(key)\n",
    "\n",
    "    return sorted(freq_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_algorithm(chunk):\n",
    "    \"\"\"Funzione che applica l'algoritmo APriori.\n",
    "    Input:\n",
    "        - chunk: partizione del file di input che contiene i basket\n",
    "    Output:\n",
    "        - freq_itemsets, lista degli itemset candidati dopo l'applicazione dell'algoritmo A-Priori\n",
    "    \"\"\"\n",
    "    baskets = list()\n",
    "    freq_itemsets = list()\n",
    "    current_freq = list()\n",
    "    for c in chunk:\n",
    "        baskets.append(c)\n",
    "    dimension = 1\n",
    "    local_supp_threshold = len(baskets) * global_supp_threshold\n",
    "    freq_singletons = get_frequent_singletons(baskets,local_supp_threshold)\n",
    "\n",
    "    for single in freq_singletons:\n",
    "        freq_itemsets.append(single)\n",
    "    \n",
    "    dimension +=1\n",
    "\n",
    "    current_freq = freq_singletons\n",
    "    \n",
    "    while True:\n",
    "        #print(f'curr freq: {current_freq}')\n",
    "        prev_frequents = current_freq\n",
    "        #print(f'prev_frequents: {prev_frequents}')\n",
    "        current_freq = getFrequents(baskets,prev_frequents,dimension,local_supp_threshold)\n",
    "        #print(f'curr freq dopo: {current_freq}')\n",
    "        for item in current_freq:\n",
    "            freq_itemsets.append(item)\n",
    "        \n",
    "        if len(current_freq) == 0:\n",
    "            break\n",
    "        dimension +=1\n",
    "\n",
    "    return freq_itemsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78039e2",
   "metadata": {},
   "source": [
    "### Map Reduce\n",
    "Viene applicato l'algoritmo **A Priori** per calcolare gli **itemset frequenti** dai quali poi otteniamo gli itemset candidati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f02ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatesItemsets = file.mapPartitions(apriori_algorithm).map(lambda item: (item,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "candidatesItemsets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "candidatesItemsets_list = candidatesItemsets.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatesItemsets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countOccurences(chunk,candidates):\n",
    "    '''Funzione che conta le occorrenze degli itemset all'interno del chunk \n",
    "        Input:\n",
    "            - chunk, porzione del file di input;\n",
    "            - candidates, lista che contine gli itemset.\n",
    "        Output:\n",
    "            - lista che contiene coppie chiave-valore dove la chiave è l'itemset e il valore è il suo conteggio\n",
    "    '''\n",
    "    itemsetOccurences = list()\n",
    "    dictionary = dict()\n",
    "    chunk_list = list(chunk)\n",
    "    for basket in chunk_list:\n",
    "        for candidate in candidates:\n",
    "            if(set(candidate[0]).issubset(set(basket))):\n",
    "                dictionary.setdefault(candidate[0],0)\n",
    "                dictionary[candidate[0]] +=1\n",
    "    \n",
    "    for key,value in dictionary.items():\n",
    "        itemsetOccurences.append((key,value)) \n",
    "    return itemsetOccurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2075acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_SecMapReduce = file.mapPartitions(lambda chunk: countOccurences(chunk,candidatesItemsets_list)).reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55466d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_SecMapReduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a512007",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_itemsetCandidates = output_SecMapReduce.count()\n",
    "num_itemsetCandidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tot_baskets = file.count()\n",
    "num_tot_baskets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd476de",
   "metadata": {},
   "source": [
    "Qui ho deciso di calcolare il supporto minimo andando a moltiplicare il numero di basket con la variabile globale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae641ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_values(item,min_value,max_value):\n",
    "    '''Funzione che normalizza i valori:\n",
    "        Input:\n",
    "            - item, l'item da normalizzare che contiene chiave e valore;\n",
    "            - min_value, il valore minimo negli itemset candidati;\n",
    "            - max_value, il valore minimo negli itemset candidati.\n",
    "        Output:\n",
    "            - ritorna una tupla che contiene chiave e valore normalizzato\n",
    "    '''\n",
    "    norm_value = (item[1]-min_value)/(max_value-min_value)\n",
    "    return (item[0],norm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f555a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = output_SecMapReduce.map(lambda item: item[1])\n",
    "min_value = values.min()\n",
    "max_value = values.max()\n",
    "normalized_secReduce = output_SecMapReduce.map(lambda item: normalize_values(item,min_value,max_value))\n",
    "normalized_secReduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "minSupportNormalized = global_supp_threshold\n",
    "minSupportNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFinale_normalizzato = normalized_secReduce.filter(lambda item: item[1] >= minSupportNormalized)\\\n",
    "    .map(lambda item:item[0]).sortBy(lambda item: len(item))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentItemset_normalizzato = outputFinale_normalizzato.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55beb7ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frequentItemset_normalizzato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bf6d0",
   "metadata": {},
   "source": [
    "Qua invece andiamo a calcolare i frequent itemset senza la normalizzazione e prendendo come supporto minimo il valore medio di tutti i valori nei candidati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getminSuppwith_avg(candidates,num_candidates):\n",
    "    '''Funzione che ritorna il supporto minimo andando\n",
    "        a calcolare il valore medio.\n",
    "        Input:\n",
    "            - candidates, itemset candidati;\n",
    "            - num_candidates;\n",
    "        Outpur:\n",
    "            supporto minimo'''\n",
    "    sums = 0\n",
    "    for c in candidates.collect():\n",
    "        sums+= c[1]\n",
    "\n",
    "    return int(sums/num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3774a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "minSupport = getminSuppwith_avg(output_SecMapReduce,num_itemsetCandidates)\n",
    "minSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFinale = output_SecMapReduce.filter(lambda item: item[1] >= minSupport)\\\n",
    "    .map(lambda item:item[0]).sortBy(lambda item: len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "frequentItemsets = outputFinale.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d175f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name_file.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salavataggio dei frequent itemset senza la normalizzazione\n",
    "\n",
    "f = open('./output/output_frequentItemsets_' + name + str(num_partition) +'.txt', 'w')\n",
    "for item in frequentItemsets:\n",
    "        if type(item) is tuple:\n",
    "            length=len(item)\n",
    "            f.write(\"(\")\n",
    "            for i in range(0,length-1):\n",
    "                f.write(str(item[i])+\",\")\n",
    "            f.write(str(item[length-1])+\")\\n\")\n",
    "        else:\n",
    "            f.write(item + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e970eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salavataggio dei frequent itemset con la normalizzazione\n",
    "\n",
    "f = open('./output/output_frequentItemsetsNormalized_' + name + str(num_partition) +'.txt', 'w')\n",
    "for item in frequentItemset_normalizzato:\n",
    "        if type(item) is tuple:\n",
    "            length=len(item)\n",
    "            f.write(\"(\")\n",
    "            for i in range(0,length-1):\n",
    "                f.write(str(item[i])+\",\")\n",
    "            f.write(str(item[length-1])+\")\\n\")\n",
    "        else:\n",
    "            f.write(item + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd05ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
